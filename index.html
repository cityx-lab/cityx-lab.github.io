<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>CityX</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>



<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">CityX: Controllable Procedural Content Generation for Unbounded 3D Cities</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="mailto:zhangshougao@email.cugb.edu.cn">Shougao Zhang</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="mailto:zhoumengqi2022@ia.ac.cn">Mengqi Zhou</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="mailto:yuxiwang93@gmail.com">Yuxi Wang</a><sup>1,3</sup>,
            </span>
            <span class="author-block">
              <a>Chuanchen Luo</a><sup>1,3</sup>,
            </span>
            <span class="author-block">
              <a>Rongyu Wang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a>Yiwei Li</a><sup>1</sup>,</span>
            <span class="author-block">
              <a>Xucheng Yin</a><sup>4</sup>,</span>
            <span class="author-block">
              <a href="mailto:zhaoxiang.zhang@ia.ac.cn">Zhaoxiang Zhang</a><sup>1,3</sup>,
            </span>
            <span class="author-block">
              <a href="mailto:jrpeng4ever@126.com">Junran Peng</a><sup>3,4</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Institute of Automation, Chinese Academy of Sciences,</span>
            <span class="author-block"><sup>2</sup>China University of Geosciences (Beijing),</span>
            <span class="author-block"><sup>3</sup>Center for Research on Intelligent Perception and Computing, CASIA</span>
            <span class="author-block"><sup>4</sup>University of Science and Technology</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2407.17572"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2407.17572"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/SGZhang608/CityX-Lab"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!--<section class="hero is-light is-small">-->
<!--  <div class="hero-body">-->
<!--    <div class="container">-->
<!--      <div id="results-carousel" class="carousel results-carousel">-->
<!--        <div class="item item-steve">-->
<!--          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./video/canyon.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-chair-tp">-->
<!--          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./video/SceneX_river_demo.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-shiba">-->
<!--          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./video/SceneX_forest_demo.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-fullbody">-->
<!--          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./video/SceneX_snow_demo.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--      </div>-->
<!--    </div>-->
<!--  </div>-->
<!--</section>-->

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <img src="./image/city_1.jpg" alt="Image 1" height="100%">
        </div>
        <div class="item item-chair-tp">
          <img src="./image/city_4.png" alt="Image 2" height="100%">
        </div>
        <div class="item item-shiba">
          <img src="./image/city_3.png" alt="Image 3" height="100%">
        </div>
        <div class="item item-fullbody">
          <img src="./image/city_2.png" alt="Image 4" height="100%">
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-light is-small">
<div class="hero-body">
  <div class="container">
    <div id="results-carousel" class="carousel results-carousel">
      <div class="item item-steve">
        <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
          <source src="./video/SceneX_1_demo.mp4"
                  type="video/mp4">
        </video>
      </div>
      <div class="item item-chair-tp">
        <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
          <source src="./video/SceneX_3_demo(1).mp4"
                  type="video/mp4">
        </video>
      </div>
      <div class="item item-shiba">
        <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
          <source src="./video/SceneX_2_demo.mp4"
                  type="video/mp4">
        </video>
      </div>
      <div class="item item-fullbody">
        <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
          <source src="./video/SceneX_4_demo(1).mp4"
                  type="video/mp4">
        </video>
      </div>
    </div>
  </div>
</div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Generating a realistic, large-scale 3D virtual city remains a complex challenge due to the involvement of numerous 3D assets, various city styles, and strict layout constraints. Existing approaches provide promising attempts at procedural content generation to create large-scale scenes using Blender agents. However, they face crucial issues such as difficulties in scaling up generation capability and achieving fine-grained control at the semantic layout level. To address these problems, we propose a novel multi-modal controllable procedural content generation method, named \mymethod, which enhances realistic, unbounded 3D city generation guided by multiple layout conditions, including OSM, semantic maps, and satellite images. Specifically, the proposed method contains a general protocol for integrating various PCG plugins and a multi-agent framework for transforming instructions into executable Blender actions. Through this effective framework, \mymethod shows the potential to build an innovative ecosystem for 3D scene generation by bridging the gap between the quality of generated assets and industrial requirements. Extensive experiments have demonstrated the effectiveness of our method in creating high-quality, diverse, and unbounded cities guided by multi-modal conditions.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">City generate demo</h2>
        <div class="publication-video">
          <iframe src="./video/SceneX_tree_demo.mp4"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 mt-5">The proposed CityX can create large-scale 3D unbounded cities automatically according to user instructions.</h2>
        <img src="./image/mainfig.jpg" alt="The proposed CityX, under the guidance of multimodal inputs including OSM data, semantic maps, and satellite images, facilitates the automatic creation of realistic large-scale 3D urban scenes.The generated models are characterized by delicate geometric structures, realistic material textures, and natural lighting, allowing for seamless deployment in the industrial pipeline." height="100%">
        <p class="content has-text-justified">
          The proposed CityX, under the guidance of multimodal inputs including OSM data, semantic maps, and satellite images, facilitates the automatic creation of realistic large-scale 3D urban scenes.The generated models are characterized by delicate geometric structures, realistic material textures, and natural lighting, allowing for seamless deployment in the industrial pipeline.
        </p>
      </div>
    </div>
    <!--/ Image section 1. -->

    <!-- Image section 2. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 mt-5">The Multi-agent Workflow</h2>
        <img src="./image/pipeline.jpg" alt="The proposed SceneX can create large-scale 3D natural scenes or unbounded cities automatically according to user instructions. The generated models are characterized by delicate geometric structures, realistic material textures, and natural lighting, allowing for seamless deployment in the industrial pipeline." height="100%">
        <p class="content has-text-justified">
          The Multi-agent framework includes a pre-processing stage and four task stages. During the pre-processing stage, the PCG is encapsulated into action functions according to the PCG Management Protocol proposed in this work. In the task stages, the planner first specifies the subtask plans based on the user's description and provided inputs. For each subtask, the planner's assistant validates the proposed subtask. If the conditions are met, the planner passes the relevant parameters to the executor to be performed in Blender. The results are then evaluated by the feedback agent. If the requirements are met, the process moves to the next subtask; if not, it reverts until all tasks are completed. This coordinated effort among agents facilitates the generation of large-scale urban scenes.
        </p>
      </div>
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">Citation</h2>
    <pre><code>@article{,
  author = {Shougao Zhang and Mengqi Zhou and Yuxi Wang and Chuanchen Luo and Rongyu Wang and Yiwei Li and Xucheng Yin and Zhaoxiang Zhang and Junran Peng},
  title  = {CityX: Controllable Procedural Content Generation for Unbounded 3D Cities},
  journal = {https://arxiv.org/pdf/2407.17572},
  year = {2024},
}</code></pre>
  </div>
</section>


</body>
</html>
